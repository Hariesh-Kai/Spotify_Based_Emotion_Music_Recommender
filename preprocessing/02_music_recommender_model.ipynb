{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df = pd.read_csv('D:/Music_Recommender/data/songs/happy.csv')\n",
    "sad_df = pd.read_csv('D:/Music_Recommender/data/songs/sad.csv')\n",
    "surprise_df = pd.read_csv('D:/Music_Recommender/data/songs/surprise.csv')\n",
    "angry_df = pd.read_csv('D:/Music_Recommender/data/songs/angry.csv')\n",
    "disgust_df = pd.read_csv('D:/Music_Recommender/data/songs/disgust.csv')\n",
    "fear_df = pd.read_csv('D:/Music_Recommender/data/songs/fear.csv')\n",
    "neutral_df = pd.read_csv('D:/Music_Recommender/data/songs/neutral.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15850</th>\n",
       "      <td>Zebrahead</td>\n",
       "      <td>Just The Tip</td>\n",
       "      <td>we got bruised wrists, kick flips, sending an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15851</th>\n",
       "      <td>Zebrahead</td>\n",
       "      <td>Let Me Go</td>\n",
       "      <td>well some wear their feelings right on their s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15852</th>\n",
       "      <td>Zebrahead</td>\n",
       "      <td>Lobotomy For Dummies</td>\n",
       "      <td>you can lie to me and say it's you i adore  \\r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15853</th>\n",
       "      <td>Zebrahead</td>\n",
       "      <td>The Setup</td>\n",
       "      <td>lie to me  \\r tell me that everything will be ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15854</th>\n",
       "      <td>Zwan</td>\n",
       "      <td>Heartsong</td>\n",
       "      <td>come in  \\r make yourself at home  \\r i'm a bi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                  song  \\\n",
       "15850  Zebrahead          Just The Tip   \n",
       "15851  Zebrahead             Let Me Go   \n",
       "15852  Zebrahead  Lobotomy For Dummies   \n",
       "15853  Zebrahead             The Setup   \n",
       "15854       Zwan             Heartsong   \n",
       "\n",
       "                                                    text  \n",
       "15850  we got bruised wrists, kick flips, sending an ...  \n",
       "15851  well some wear their feelings right on their s...  \n",
       "15852  you can lie to me and say it's you i adore  \\r...  \n",
       "15853  lie to me  \\r tell me that everything will be ...  \n",
       "15854  come in  \\r make yourself at home  \\r i'm a bi...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38062, 4)\n",
      "(15855, 4)\n",
      "(314, 4)\n",
      "(181, 4)\n",
      "(32, 4)\n",
      "(1677, 4)\n",
      "(1529, 4)\n"
     ]
    }
   ],
   "source": [
    "print(happy_df.shape)\n",
    "print(sad_df.shape)\n",
    "print(surprise_df.shape)\n",
    "print(angry_df.shape)\n",
    "print(disgust_df.shape)\n",
    "print(fear_df.shape)\n",
    "print(neutral_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df=happy_df.drop('link',axis=1).reset_index(drop=True)\n",
    "sad_df=sad_df.drop('link',axis=1).reset_index(drop=True)\n",
    "surprise_df=surprise_df.drop('link',axis=1).reset_index(drop=True)\n",
    "angry_df=angry_df.drop('link',axis=1).reset_index(drop=True)\n",
    "disgust_df=disgust_df.drop('link',axis=1).reset_index(drop=True)\n",
    "fear_df=fear_df.drop('link',axis=1).reset_index(drop=True)\n",
    "neutral_df=neutral_df.drop('link',axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38062, 3)\n",
      "(15855, 3)\n",
      "(314, 3)\n",
      "(181, 3)\n",
      "(32, 3)\n",
      "(1677, 3)\n",
      "(1529, 3)\n"
     ]
    }
   ],
   "source": [
    "print(happy_df.shape)\n",
    "print(sad_df.shape)\n",
    "print(surprise_df.shape)\n",
    "print(angry_df.shape)\n",
    "print(disgust_df.shape)\n",
    "print(fear_df.shape)\n",
    "print(neutral_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text Cleaning/Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_df['text']=happy_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)\n",
    "sad_df['text']=sad_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)\n",
    "surprise_df['text']=surprise_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)\n",
    "angry_df['text']=angry_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)\n",
    "disgust_df['text']=disgust_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)\n",
    "fear_df['text']=fear_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)\n",
    "neutral_df['text']=neutral_df['text'].str.lower().replace(r'^\\w\\s',' ').replace(r'\\n', ' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\harie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\harie\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "# Ensure nltk data path is set correctly\n",
    "\n",
    "# Download 'punkt' and 'punkt_tab' resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')  # This is the missing resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(txt):\n",
    "    tokenized = nltk.word_tokenize(txt)\n",
    "    a = [stemmer.stem(w) for w in tokenized]\n",
    "    return \" \".join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       pued escuchar fernando ? me recuerda tiempo at...\n",
       "1       you feel bad , let me tell you , we all get th...\n",
       "2       they came from the hill and they came from the...\n",
       "3       everybodi scream when i kiss the teacher and t...\n",
       "4       alway have , alway will i wa mesmer when i fir...\n",
       "                              ...                        \n",
       "1524    got a new haircut it cost me just six buck fil...\n",
       "1525    walter quit the raf when there wa no good air ...\n",
       "1526    i went from old school chevi to drop top porsc...\n",
       "1527    ca n't get down i 've seen the light i made th...\n",
       "1528    i see you hide do you have pride afraid to sha...\n",
       "Name: text, Length: 1529, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "happy_df['text'].apply(lambda x: token(x))\n",
    "sad_df['text'].apply(lambda x: token(x))\n",
    "surprise_df['text'].apply(lambda x: token(x))\n",
    "angry_df['text'].apply(lambda x: token(x))\n",
    "disgust_df['text'].apply(lambda x: token(x))\n",
    "fear_df['text'].apply(lambda x: token(x))\n",
    "neutral_df['text'].apply(lambda x: token(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid = TfidfVectorizer(analyzer='word',stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "happy_matrix =tfid.fit_transform(happy_df['text'])\n",
    "sad_matrix =tfid.fit_transform(sad_df['text'])\n",
    "surprise_matrix =tfid.fit_transform(surprise_df['text'])\n",
    "angry_matrix =tfid.fit_transform(angry_df['text'])\n",
    "disgust_matrix =tfid.fit_transform(disgust_df['text'])\n",
    "fear_matrix =tfid.fit_transform(fear_df['text'])\n",
    "neutral_matrix =tfid.fit_transform(neutral_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to float32 to save memory\n",
    "happy_matrix = happy_matrix.astype('float32')\n",
    "sad_matrix = sad_matrix.astype('float32')\n",
    "surprise_matrix = surprise_matrix.astype('float32')\n",
    "angry_matrix = angry_matrix.astype('float32')\n",
    "disgust_matrix = disgust_matrix.astype('float32')\n",
    "fear_matrix = fear_matrix.astype('float32')\n",
    "neutral_matrix = neutral_matrix.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert to sparse matrix\n",
    "happy_matrix_sparse = csr_matrix(happy_matrix)\n",
    "happy_similar = cosine_similarity(happy_matrix_sparse)\n",
    "\n",
    "# Repeat for other emotion matrices\n",
    "sad_matrix_sparse = csr_matrix(sad_matrix)\n",
    "sad_similar = cosine_similarity(sad_matrix_sparse)\n",
    "\n",
    "surprise_matrix_sparse = csr_matrix(surprise_matrix)\n",
    "surprise_similar = cosine_similarity(surprise_matrix_sparse)\n",
    "\n",
    "angry_matrix_sparse = csr_matrix(angry_matrix)\n",
    "angry_similar = cosine_similarity(angry_matrix_sparse)\n",
    "\n",
    "disgust_matrix_sparse = csr_matrix(disgust_matrix)\n",
    "disgust_similar = cosine_similarity(disgust_matrix_sparse)\n",
    "\n",
    "fear_matrix_sparse = csr_matrix(fear_matrix)\n",
    "fear_similar = cosine_similarity(fear_matrix_sparse)\n",
    "\n",
    "neutral_matrix_sparse = csr_matrix(neutral_matrix)\n",
    "neutral_similar = cosine_similarity(neutral_matrix_sparse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recommender Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def happy_recommender(song_name):\n",
    "    idx = happy_df[happy_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(happy_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    happy_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "         happy_song.append(happy_df.iloc[s_id[0]]['song'])\n",
    "    return happy_song\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sad_recommender(song_name):\n",
    "    idx = sad_df[sad_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(sad_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    sad_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        sad_song.append(sad_df.iloc[s_id[0]]['song'])\n",
    "    return sad_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def surprise_recommender(song_name):\n",
    "    idx = surprise_df[surprise_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(surprise_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    surprise_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        surprise_song.append(surprise_df.iloc[s_id[0]]['song'])\n",
    "    return surprise_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def angry_recommender(song_name):\n",
    "    idx = angry_df[angry_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(angry_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    angry_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        angry_song.append(angry_df.iloc[s_id[0]]['song'])\n",
    "    return angry_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disgust_recommender(song_name):\n",
    "    idx = disgust_df[disgust_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(disgust_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    disgust_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        disgust_song.append(disgust_df.iloc[s_id[0]]['song'])\n",
    "    return  disgust_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fear_recommender(song_name):\n",
    "    idx = fear_df[fear_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(fear_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    fear_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        fear_song.append(fear_df.iloc[s_id[0]]['song'])\n",
    "    return fear_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neutral_recommender(song_name):\n",
    "    idx = neutral_df[neutral_df['song']==song_name].index[0]\n",
    "    distance = sorted(list(enumerate(neutral_similar[idx])),reverse=True,key=lambda x:x[1])\n",
    "    neutral_song = []\n",
    "    for s_id in distance[1:21]:\n",
    "        neutral_song.append(neutral_df.iloc[s_id[0]]['song'])\n",
    "    return neutral_song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Don't Cry No More\",\n",
       " \"I've Got To Be Free\",\n",
       " 'Ride The Wild Wind',\n",
       " 'Hey Stoopid',\n",
       " 'Between Heaven And Hell',\n",
       " 'Peacemaker',\n",
       " 'Hey Hey, My My',\n",
       " 'False Alarm',\n",
       " 'Over The Hill',\n",
       " 'I Can Do Better',\n",
       " 'This Is My Party',\n",
       " 'Make Some Noise',\n",
       " 'Hey Girl',\n",
       " 'Hey Now',\n",
       " \"Don't Keep Me Waiting\",\n",
       " 'Hey Girl',\n",
       " 'Hey You',\n",
       " 'Hey Hey, My My',\n",
       " 'Wild Horses',\n",
       " 'Hey Gypsy']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sad_recommender('Just The Tip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directories to save the files\n",
    "similarity_directory = 'D:/Music_Recommender/pickle/similarity/'\n",
    "dataframe_directory = 'D:/Music_Recommender/pickle/dataframe/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save similarity matrices for each emotion\n",
    "pickle.dump(happy_similar, open(f'{similarity_directory}happy_similarity.pkl', 'wb'))\n",
    "pickle.dump(sad_similar, open(f'{similarity_directory}sad_similarity.pkl', 'wb'))\n",
    "pickle.dump(surprise_similar, open(f'{similarity_directory}surprise_similarity.pkl', 'wb'))\n",
    "pickle.dump(angry_similar, open(f'{similarity_directory}angry_similarity.pkl', 'wb'))\n",
    "pickle.dump(disgust_similar, open(f'{similarity_directory}disgust_similarity.pkl', 'wb'))\n",
    "pickle.dump(fear_similar, open(f'{similarity_directory}fear_similarity.pkl', 'wb'))\n",
    "pickle.dump(neutral_similar, open(f'{similarity_directory}neutral_similarity.pkl', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save DataFrames for each emotion\n",
    "pickle.dump(happy_df, open(f'{dataframe_directory}happy_df.pkl', 'wb'))\n",
    "pickle.dump(sad_df, open(f'{dataframe_directory}sad_df.pkl', 'wb'))\n",
    "pickle.dump(surprise_df, open(f'{dataframe_directory}surprise_df.pkl', 'wb'))\n",
    "pickle.dump(angry_df, open(f'{dataframe_directory}angry_df.pkl', 'wb'))\n",
    "pickle.dump(disgust_df, open(f'{dataframe_directory}disgust_df.pkl', 'wb'))\n",
    "pickle.dump(fear_df, open(f'{dataframe_directory}fear_df.pkl', 'wb'))\n",
    "pickle.dump(neutral_df, open(f'{dataframe_directory}neutral_df.pkl', 'wb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
